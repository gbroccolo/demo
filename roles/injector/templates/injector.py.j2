#!/usr/bin/env python

"""
Injector - batch ingestion of data after some cleaning

Usage: injector.py [-w WORKERS] -d datasource
"""

import argparse
import psycopg2
import psycopg2.extras
import threading
import csv
import os
import os.path
import time
import sys
import logging


class InjectorService:

    def __init__(self, datasource, workers, logger):
        self.running = True
        self.csv = [{{ injector_csvs }}]
        self.start = False
        self.session = False
        self.datasource = datasource
        self.logger = logger

    @staticmethod
    def is_int(s):
        try:
            if int(s) >= 0:
                return True
            return False
        except ValueError:
            return False

    def worker(self, reader, datasource, conn):
        self.logger.debug('starting parallel worker...')

        SQL_INS = ""
        if datasource == '3':
            SQL_INS = """
            INSERT INTO sessions(sessionid,
                                 device,
                                 duration)
                VALUES (%s, %s, %s)
            """
        elif datasource == '2':
            SQL_INS = """
            INSERT INTO clicks(sessionid,
                               pageviewid,
                               total_clicks,
                               resp_clicks,
                               unresp_clicks)
                VALUES (%s, %s, %s, %s, %s)
            """
        elif datasource == '1':
            SQL_INS = """
            INSERT INTO mouse_moves(sessionid,
                                    pageviewid,
                                    mouse_distance,
                                    duration_moves,
                                    no_moves)
                VALUES (%s, %s, %s, %s, %s)
            """
        else:
            self.logger.error('Unable to parse datasource')

        cur = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
        reader.next()
        for rec in reader:
            entry = ()
            for att in rec:
                # this is a PK/FK - skip the entry, this info cannot
                # be referenced to anything
                if rec[0] == '':
                    break
                if InjectorService.is_int(att):
                    entry += (att,)
                else:
                    entry += (None,)
            if entry:
                try:
                    cur.execute(INSERT_SQL, entry)
                except psycopg2.IntegrityError:
                    self.logger.warn('Record %s not instered' % rec)
                    conn.rollback()
                except psycopg2.DataError:
                    self.logger.error('ERROR during insertion!! Exit now.')
                    sys.exit(1)
                else:
                    conn.commit()
            else:
                self.logger.warn('Record %s not instered' % rec)

        cur.close()

    def injector(self, datasource):
        self.logger.info(('Thread injector for source '
                          '%s started') % datasource)

        while self.running:
            if not self.start:
                self.logger.info('no new data for %s, sleeping.' %
                                 datasource)
                time.sleep(5)
                continue
            path = os.path.join(self.datasource, datasource)
            if os.path.isfile(path):
                if self.session or \
                  datasource.split('_')[2] != '3':
                    pass
                else:
                    self.logger.info('no new data for %s, sleeping.' %
                                     datasource)
                    time.sleep(5)
                try:
                    self.logger.debug(' connectiong to postgres...')
                    conn = psycopg2.connect(dbname="demo",
                                            user="demo",
                                            password="demo",
                                            port="5432")
                except:
                    self.logger.error('Could not connect to postgresql')
                    sys.exit(1)

                with open(path) as csvfile:
                    reader = csv.reader(csvfile)
                    self.logger.debug('   starting insertion ')

                    self.worker(reader,
                                datasource.split('_')[2], 
                                conn)

                    conn.close()

                    if datasource.split('_')[2] == '3':
                        self.session = True
                    ren = os.path.join(self.datasource,
                                       os.path.splitext(
                                           datasource)[0] + ".done")
                    os.rename(path, ren)
            else:
                self.logger.info('no new data for %s, sleeping.' % datasource)
                time.sleep(5)
                continue

    def coordinator(self):
        self.logger.info('Thread coordinator is started')

        while self.running:
            d = 0
            for f in self.csv:
                path = os.path.join(self.datasource, f)
                if os.path.isfile(path):
                    d += 1
            if d == len(self.csv) or (self.session and d >= 1):
                self.start = True
            else:
                self.start = False

            d = 0
            for g in os.listdir(self.datasource):
                if g.endswith('.done'):
                    d += 1
            if d == len(self.csv):
                self.logger.info("Batch ingestion concluded!")
                self.logger.info("   --- Deleting .done files!! --- ")
                os.remove(os.path.join(self.datasource, g))

            time.sleep(5)

    def launch(self):
        self.running = True
        self.threads = []

        self.logger.info('Starting coordinator workers...')
        c = threading.Thread(target=self.coordinator)
        c.setDaemon(True)
        c.start()
        self.threads.append(c)

        self.logger.info('Starting injector workers...')

        for f in self.csv:
            t = threading.Thread(target=self.injector, args=(f,))
            t.setDaemon(True)
            t.start()
            self.threads.append(t)

        self.logger.info('Ready to inject...')

        while self.running:
            time.sleep(1000)
            for t in self.threads:
                if not t.is_alive():
                    self.logger.error('A thread closed unexpectedly!!')
                    self.running = False

        for t in self.threads:
            t.join()

        print 'All injector threads are going down!'


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-d', '--datasource', help='where data is placed',
                        required=True)

    args = parser.parse_args()
    datasource = args.datasource

    if datasource is None:
        print >> sys.stderr, '-d option is mandatory'
        sys.exit(1)

    logger = set_loggers()

    i = InjectorService(datasource=datasource, logger=logger)
    i.launch()


def set_loggers():
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.{{ injector_log_level }})
    handler = logging.FileHandler("{{ injector_log_destination }}")
    handler.setLevel(logging.{{ injector_log_level }})
    formatter = logging.Formatter('%(asctime)s - %(name)s \
                                  - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    return logger


if __name__ == '__main__':
    sys.exit(main())
